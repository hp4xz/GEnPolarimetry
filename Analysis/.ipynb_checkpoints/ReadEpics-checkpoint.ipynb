{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cc0929",
   "metadata": {},
   "source": [
    "# 10/01-12/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d1b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT.csv\n",
      "TC.csv\n",
      "PC.csv\n",
      "0 ['--- HaHPE1313ACh15 ---']\n",
      "226420 ['--- HaHPE1313ACh16 ---']\n",
      "448413 ['--- HaHPE1313ACh17 ---']\n",
      "686399 ['--- HaHPE1313ACh18 ---']\n",
      "0 ['--- HaHPE1313ACh13 ---']\n",
      "221030 ['--- HaHPE1313ACh14 ---']\n",
      "0 ['--- HaHPE1313ACh11 ---']\n",
      "229528 ['--- HacOMEGA_RTD ---']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:5071: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from math import *\n",
    "from copy import deepcopy\n",
    "\n",
    "import csv\n",
    "FileList=['TT.csv','TC.csv','PC.csv']\n",
    "# Open the CSV file\n",
    "with open('EpicsTempData/TC.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  tcdata = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    tcdata.append(row)\n",
    "\n",
    "with open('EpicsTempData/TT.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  ttdata = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    ttdata.append(row)\n",
    "\n",
    "with open('EpicsTempData/PC.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  pcdata = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    pcdata.append(row)\n",
    "\n",
    "\n",
    "\n",
    "for i, name in enumerate(FileList):\n",
    "    print(name)\n",
    "\n",
    "tcIndices=np.empty(0)\n",
    "pcIndices=np.empty(0)\n",
    "ttIndices=np.empty(0)\n",
    "\n",
    "for i,row in enumerate(tcdata):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        tcIndices=np.append(tcIndices,i)\n",
    "        print(i,row)\n",
    "        \n",
    "for i,row in enumerate(ttdata):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        ttIndices=np.append(ttIndices,i)\n",
    "        print(i,row)\n",
    "\n",
    "for i,row in enumerate(pcdata):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        pcIndices=np.append(pcIndices,i)\n",
    "        print(i,row)\n",
    "tcIndices=tcIndices.astype(int)    \n",
    "ttIndices=ttIndices.astype(int)\n",
    "pcIndices=pcIndices.astype(int)\n",
    "\n",
    "tc1=tcdata[tcIndices[0]:tcIndices[1]]\n",
    "tc2=tcdata[tcIndices[1]:tcIndices[2]]\n",
    "tc3=tcdata[tcIndices[2]:tcIndices[3]]\n",
    "tc4=tcdata[tcIndices[3]:]\n",
    "\n",
    "tt1=ttdata[ttIndices[0]:ttIndices[1]]\n",
    "tt2=ttdata[ttIndices[1]:]\n",
    "\n",
    "pc1=pcdata[pcIndices[0]:pcIndices[1]]\n",
    "pc2=pcdata[pcIndices[1]:]\n",
    "\n",
    "\n",
    "tc1=np.delete(tc1,0)\n",
    "tc2=np.delete(tc2,0)\n",
    "tc3=np.delete(tc3,0)\n",
    "tc4=np.delete(tc4,0)\n",
    "\n",
    "tt1=np.delete(tt1,0)\n",
    "tt2=np.delete(tt2,0)\n",
    "\n",
    "pc1=np.delete(pc1,0)\n",
    "pc2=np.delete(pc2,0)\n",
    "\n",
    "fun=[tc1,tc2,tc3,tc4,pc1,pc2,tt1,tt2]\n",
    "for j,data in enumerate(fun):\n",
    "    for i in range(0,len(data)):\n",
    "        data[i][0]=data[i][0].replace('-','')\n",
    "        data[i][0]=data[i][0].replace(':','')\n",
    "        data[i][0]=data[i][0].replace(' ','_')\n",
    "        \n",
    "        if data[i][1]=='null':\n",
    "\n",
    "            data[i][1]='0'\n",
    "        \n",
    "    data=np.concatenate(data)\n",
    "    data=np.reshape(data,(int(len(data)/2),2))\n",
    "    data=np.transpose(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fun[j]=data\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "tc1,tc2,tc3,tc4,pc1,pc2,tt1,tt2=fun\n",
    "s1=10\n",
    "s2=33.32\n",
    "tc1[1]=(tc1[1].astype(float)*s1).astype(str)\n",
    "tc2[1]=(tc2[1].astype(float)*s1).astype(str)\n",
    "tc3[1]=(tc3[1].astype(float)*s1).astype(str)\n",
    "tc4[1]=(tc4[1].astype(float)*s1).astype(str)\n",
    "pc1[1]=(pc1[1].astype(float)*s2).astype(str)\n",
    "tt1[1]=(tt1[1].astype(float)*s1).astype(str)\n",
    "tt2[1]=(tt2[1].astype(float)*s1).astype(str)\n",
    "\n",
    "#10/01-12/16\n",
    "np.save('Epics_NP_Arrays/tc1.npy',tc1)\n",
    "np.save('Epics_NP_Arrays/tc2.npy',tc2)\n",
    "np.save('Epics_NP_Arrays/tc3.npy',tc3)\n",
    "np.save('Epics_NP_Arrays/tc4.npy',tc4)\n",
    "\n",
    "np.save('Epics_NP_Arrays/pc1.npy',pc1)\n",
    "np.save('Epics_NP_Arrays/pc2.npy',pc2)\n",
    "\n",
    "np.save('Epics_NP_Arrays/tt1.npy',tt1)\n",
    "np.save('Epics_NP_Arrays/tt2.npy',tt2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b392a63",
   "metadata": {},
   "source": [
    "# 12/16/-03/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileList=['TT2.csv','TC2.csv','PC2.csv']\n",
    "# Open the CSV file\n",
    "with open('EpicsTempData/TC2.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  tcdata = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    tcdata.append(row)\n",
    "\n",
    "with open('EpicsTempData/TT2.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  ttdata = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    ttdata.append(row)\n",
    "\n",
    "with open('EpicsTempData/PC2.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  pcdata = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    pcdata.append(row)\n",
    "\n",
    "\n",
    "\n",
    "for i, name in enumerate(FileList):\n",
    "    print(name)\n",
    "\n",
    "tcIndices=np.empty(0)\n",
    "pcIndices=np.empty(0)\n",
    "ttIndices=np.empty(0)\n",
    "\n",
    "for i,row in enumerate(tcdata):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        tcIndices=np.append(tcIndices,i)\n",
    "        print(i,row)\n",
    "        \n",
    "for i,row in enumerate(ttdata):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        ttIndices=np.append(ttIndices,i)\n",
    "        print(i,row)\n",
    "\n",
    "for i,row in enumerate(pcdata):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        pcIndices=np.append(pcIndices,i)\n",
    "        print(i,row)\n",
    "tcIndices=tcIndices.astype(int)    \n",
    "ttIndices=ttIndices.astype(int)\n",
    "pcIndices=pcIndices.astype(int)\n",
    "\n",
    "tc1=tcdata[tcIndices[0]:tcIndices[1]]\n",
    "tc2=tcdata[tcIndices[1]:tcIndices[2]]\n",
    "tc3=tcdata[tcIndices[2]:tcIndices[3]]\n",
    "tc4=tcdata[tcIndices[3]:]\n",
    "\n",
    "tt1=ttdata[ttIndices[0]:ttIndices[1]]\n",
    "tt2=ttdata[ttIndices[1]:]\n",
    "\n",
    "pc1=pcdata[pcIndices[0]:pcIndices[1]]\n",
    "pc2=pcdata[pcIndices[1]:]\n",
    "\n",
    "\n",
    "tc1=np.delete(tc1,0)\n",
    "tc2=np.delete(tc2,0)\n",
    "tc3=np.delete(tc3,0)\n",
    "tc4=np.delete(tc4,0)\n",
    "\n",
    "tt1=np.delete(tt1,0)\n",
    "tt2=np.delete(tt2,0)\n",
    "\n",
    "pc1=np.delete(pc1,0)\n",
    "pc2=np.delete(pc2,0)\n",
    "\n",
    "fun=[tc1,tc2,tc3,tc4,pc1,pc2,tt1,tt2]\n",
    "for j,data in enumerate(fun):\n",
    "    for i in range(0,len(data)):\n",
    "        data[i][0]=data[i][0].replace('-','')\n",
    "        data[i][0]=data[i][0].replace(':','')\n",
    "        data[i][0]=data[i][0].replace(' ','_')\n",
    "        \n",
    "        if data[i][1]=='null':\n",
    "\n",
    "            data[i][1]='0'\n",
    "        \n",
    "    data=np.concatenate(data)\n",
    "    data=np.reshape(data,(int(len(data)/2),2))\n",
    "    data=np.transpose(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fun[j]=data\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "tc1,tc2,tc3,tc4,pc1,pc2,tt1,tt2=fun\n",
    "s1=10\n",
    "s2=33.32\n",
    "tc1[1]=(tc1[1].astype(float)*s1).astype(str)\n",
    "tc2[1]=(tc2[1].astype(float)*s1).astype(str)\n",
    "tc3[1]=(tc3[1].astype(float)*s1).astype(str)\n",
    "tc4[1]=(tc4[1].astype(float)*s1).astype(str)\n",
    "pc1[1]=(pc1[1].astype(float)*s2).astype(str)\n",
    "tt1[1]=(tt1[1].astype(float)*s1).astype(str)\n",
    "tt2[1]=(tt2[1].astype(float)*s1).astype(str)\n",
    "\n",
    "#10/01-12/16\n",
    "np.save('Epics_NP_Arrays/tc1.npy',tc1)\n",
    "np.save('Epics_NP_Arrays/tc2.npy',tc2)\n",
    "np.save('Epics_NP_Arrays/tc3.npy',tc3)\n",
    "np.save('Epics_NP_Arrays/tc4.npy',tc4)\n",
    "\n",
    "np.save('Epics_NP_Arrays/pc1.npy',pc1)\n",
    "np.save('Epics_NP_Arrays/pc2.npy',pc2)\n",
    "\n",
    "np.save('Epics_NP_Arrays/tt1.npy',tt1)\n",
    "np.save('Epics_NP_Arrays/tt2.npy',tt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e475d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20221004_141502', '20221004_141509', '20221004_141511',\n",
       "       '20221004_141601', '20221004_141603', '20221004_141611',\n",
       "       '20221004_141714', '20221004_141722', '20221004_141727',\n",
       "       '20221004_141804'], dtype='<U18')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc1[0][100:110]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02809510",
   "metadata": {},
   "source": [
    "# Determine Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7743e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from math import *\n",
    "from copy import deepcopy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dcdbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EpicsTempData/TCScaled.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  scaledTC = []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    scaledTC.append(row)\n",
    "with open('EpicsTempData/TCRaw.csv', 'r') as file:\n",
    "  # Read the CSV file\n",
    "  reader = csv.reader(file)\n",
    "\n",
    "  # Create an empty list to store the data\n",
    "  rawTC= []\n",
    "\n",
    "  # Loop through the rows in the CSV file\n",
    "  for row in reader:\n",
    "    # Add the row to the data list\n",
    "    rawTC.append(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7302b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTCI=np.empty(0)\n",
    "scaledTCI=np.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3303ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['--- HaHPE1313ACh15 ---']\n",
      "101452 ['--- HaHPE1313ACh16 ---']\n",
      "189822 ['--- HaHPE1313ACh17 ---']\n",
      "292830 ['--- HaHPE1313ACh18 ---']\n",
      "0 ['--- HaHPE1313ACh15:temp ---']\n",
      "145925 ['--- HaHPE1313ACh16:temp ---']\n",
      "284044 ['--- HaHPE1313ACh17:temp ---']\n",
      "432822 ['--- HaHPE1313ACh18:temp ---']\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(rawTC):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        rawTCI=np.append(rawTCI,i)\n",
    "        print(i,row)\n",
    "        \n",
    "for i,row in enumerate(scaledTC):\n",
    "    \n",
    "    if len(row) == 1:\n",
    "        scaledTCI=np.append(scaledTCI,i)\n",
    "        print(i,row)\n",
    "        \n",
    "rawTCI=rawTCI.astype(int)\n",
    "scaledTCI=scaledTCI.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba5198cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc1R=rawTC[rawTCI[0]:rawTCI[1]]\n",
    "tc2R=rawTC[rawTCI[1]:rawTCI[2]]\n",
    "tc3R=rawTC[rawTCI[2]:rawTCI[3]]\n",
    "tc4R=rawTC[rawTCI[3]:]\n",
    "\n",
    "tc1R=np.delete(tc1R,0)\n",
    "tc2R=np.delete(tc2R,0)\n",
    "tc3R=np.delete(tc3R,0)\n",
    "tc4R=np.delete(tc4R,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f557ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc1S=scaledTC[scaledTCI[0]:scaledTCI[1]]\n",
    "tc2S=scaledTC[scaledTCI[1]:scaledTCI[2]]\n",
    "tc3S=scaledTC[scaledTCI[2]:scaledTCI[3]]\n",
    "tc4S=scaledTC[scaledTCI[3]:]\n",
    "\n",
    "tc1S=np.delete(tc1S,0)\n",
    "tc2S=np.delete(tc2S,0)\n",
    "tc3S=np.delete(tc3S,0)\n",
    "tc4S=np.delete(tc4S,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a4e9d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.951643201761023"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.concatenate(tc1S)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc1S=np.transpose(data)[1].astype(float)\n",
    "data=np.concatenate(tc1R)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc1R=np.transpose(data)[1].astype(float)\n",
    "\n",
    "np.mean(tc1S)/np.mean(tc1R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4894c541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.874407512329704"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.concatenate(tc2S)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc2S=np.transpose(data)[1].astype(float)\n",
    "data=np.concatenate(tc2R)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc2R=np.transpose(data)[1].astype(float)\n",
    "\n",
    "np.mean(tc2S)/np.mean(tc2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36222941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.884087057783574"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.concatenate(tc3S)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc3S=np.transpose(data)[1].astype(float)\n",
    "data=np.concatenate(tc3R)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc3R=np.transpose(data)[1].astype(float)\n",
    "\n",
    "np.mean(tc3S)/np.mean(tc3R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9f459ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.91892477190032"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.concatenate(tc4S)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc4S=np.transpose(data)[1].astype(float)\n",
    "data=np.concatenate(tc4R)\n",
    "data=np.reshape(data,(int(len(data)/2),2))\n",
    "tc4R=np.transpose(data)[1].astype(float)\n",
    "\n",
    "np.mean(tc4S)/np.mean(tc4R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7f042",
   "metadata": {},
   "source": [
    "for the tc and tt the scale is 10\n",
    "for the pc the scale is 33.32\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
